# app/dependencies.py
import time
import logging
import pandas as pd
import torch

from app.models.anime_title_searcher import AnimeTitleSearcher
from app.models.matrix_factorzation import MatrixFactorization
from app.services.anime_translator_infer_service import load_translator_model
from app.init_data import init_data

# ===== ì „ì—­ ê°ì²´ =====
title_searcher = None
recommender = None
translator_model = None
translator_tokenizer = None
anime_meta_df: pd.DataFrame | None = None
mf_items = None
anime_id_to_item_idx = None


async def init_models():
    init_data()

    global title_searcher, recommender, translator_model, translator_tokenizer
    global anime_meta_df, mf_items, anime_id_to_item_idx

    print("\n==== [INIT] ëª¨ë¸ ì´ˆê¸°í™” ì‹œì‘ ====\n")
    total_start = time.perf_counter()

    # -----------------------------
    # 1) Anime Title Searcher ë¡œë“œ
    # -----------------------------
    t1 = time.perf_counter()
    print("[1] Anime Metadata ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")

    # ğŸ”¥ ë°”ë¡œ anime_meta_dfì— í• ë‹¹
    anime_meta_df = pd.read_csv(
        "app/data/animelist-dataset/anime-dataset-2023.csv"
    )
    print(f"[1] CSV ë¡œë“œ ì™„ë£Œ: {len(anime_meta_df)} rows")

    print("[1] AnimeTitleSearcher ì„ë² ë”© êµ¬ì¶• ì¤‘ (SentenceTransformer ë¡œë”© í¬í•¨)...")
    title_searcher = AnimeTitleSearcher().fit(anime_meta_df)
    t1_end = time.perf_counter()
    print(f"[1] AnimeTitleSearcher ì¤€ë¹„ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {t1_end - t1:.3f}ì´ˆ)\n")

    # -----------------------------
    # 2) Matrix Factorization ì¶”ì²œ ëª¨ë¸
    # -----------------------------
    t2 = time.perf_counter()
    print("[2] ì¶”ì²œ ëª¨ë¸(MF) ê°€ì¤‘ì¹˜ ë¡œë“œ ì¤‘...")

    state = torch.load(
        "app/models/weights/mf_weight.pt",
        map_location="cpu",
        weights_only=True,
    )

    num_users = state["user_factors.weight"].shape[0]
    num_items = state["item_factors.weight"].shape[0]
    print(f"[2] num_users={num_users}, num_items={num_items}")

    recommender = MatrixFactorization(num_users, num_items, factors=64)
    recommender.load_state_dict(state)
    recommender.eval()

    t2_end = time.perf_counter()
    print(f"[2] MF ì¶”ì²œ ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {t2_end - t2:.3f}ì´ˆ)\n")

    # -----------------------------
    # 3) MF item ë§¤í•‘ ë³µì›
    # -----------------------------
    t3 = time.perf_counter()
    print("[3] MF item ë§¤í•‘ ë³µì› ì¤‘...")

    ratings = (
        pd.read_csv(
            "app/data/animelist-dataset/users-score-2023.csv",
            usecols=["user_id", "anime_id", "rating"],
        )
        .dropna()
        .query("rating > 0")
    )
    top_users = ratings["user_id"].value_counts().head(500).index
    filtered = ratings[ratings["user_id"].isin(top_users)]

    _, users = pd.factorize(filtered["user_id"])
    item_ids, items = pd.factorize(
        filtered["anime_id"])  # items: unique anime_id ë°°ì—´

    mf_items = items
    anime_id_to_item_idx = {
        int(anime_id): int(idx) for idx, anime_id in enumerate(items)
    }

    t3_end = time.perf_counter()
    print(
        f"[3] MF item ë§¤í•‘ ì¤€ë¹„ ì™„ë£Œ | unique_items={len(mf_items)} "
        f"(ì†Œìš”ì‹œê°„: {t3_end - t3:.3f}ì´ˆ)"
    )

    # -----------------------------
    # 4) ë²ˆì—­ ëª¨ë¸ ë¡œë“œ
    # -----------------------------
    t4 = time.perf_counter()
    print("[4] ë²ˆì—­ ëª¨ë¸ ë¡œë“œ ì¤‘...")

    adapter_dir = "app/models/weights/mbart_ja2ko_title_lora_mps/adapter"
    translator_model, translator_tokenizer = load_translator_model(
        adapter_dir=adapter_dir
    )

    t4_end = time.perf_counter()
    print(f"[4] ë²ˆì—­ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {t4_end - t4:.3f}ì´ˆ)\n")

    total_end = time.perf_counter()
    print(
        f"\n==== [INIT] ì „ì²´ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ | ì´ ì†Œìš”ì‹œê°„: {total_end - total_start:.3f}ì´ˆ ====\n"
    )
